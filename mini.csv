"import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error,r2_score
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import MinMaxScaler
from keras.optimizers import SGD
from keras.utils import np_utils
from sklearn.preprocessing import LabelEncoder


data = pd.read_csv(""Ionosphere.csv"",sep = ',')
data


data.describe()

data.isnull().sum()


X = data.iloc[:,:34]
X

Y = data.iloc[:,34:]
Y


X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size = 20 , random_state = 1)


model = LinearRegression()
model.fit(X_train,Y_train)


y_pred = model.predict(X_test)
y_pred


error = mean_absolute_error(y_pred,Y_test)
print(error)


score = r2_score(y_pred,Y_test)
print(score)


model = SGDRegressor(loss='squared_error',penalty='l2', alpha=0.0001)
model.fit(X_train,Y_train)


y_pred = model.predict(X_test)
y_pred


error = mean_absolute_error(y_pred,Y_test)
print(error)


score = r2_score(y_pred,Y_test)
print(score)


def SGD(data, learning_rate=0.2, n_epochs=1000, k=40):
    w = np.random.randn(1,data.shape[1]-1)
    b = 0
    epoch=1
    
    while epoch <= n_epochs:
        temp = data.sample(k)
        y = np.array(temp[""Class""])
        x  =np.array(temp.drop(""Class"",axis=1))
        L_w = w
        L_b = b
        loss = 0
        y_pred = []

        for i in range(k): 
            L_w = (-2/k * x[i]) * (y[i] - np.dot(x[i],w.T) - b)
            L_b = (-2/k) * (y[i] - np.dot(x[i],w.T) - b)
            w = w - learning_rate * L_w
            b = b - learning_rate * L_b
            
        epoch += 1
        learning_rate = learning_rate/1.02
        
    return w,b


def predict(x,w,b):
    y_pred = []
    for i in range(len(x)):
        y = np.asscalar(np.dot(w,x[i])+b)
        y_pred.append(y)
    return np.array(y_pred)


import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

w,b = SGD(data)
x_test = np.array(X_test)
y_test = np.array(Y_test)

from sklearn import preprocessing
scaler = preprocessing.StandardScaler()
x_test = scaler.fit_transform(X_test)
y_pred = predict(x_test,w,b)

print('Mean Squared Error :',mean_squared_error(y_test, y_pred))


def predict(x,w,b):
    y_pred = []
    for i in range(len(x)):
        y = np.asscalar(np.dot(w,x[i])+b)
        y_pred.append(y)
    return np.array(y_pred)


import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

w,b = SGD(data)
x_test = np.array(X_test)
y_test = np.array(Y_test)

from sklearn import preprocessing
scaler = preprocessing.StandardScaler()
x_test = scaler.fit_transform(X_test)
y_pred = predict(x_test,w,b)

print('Mean Squared Error :',mean_squared_error(y_test, y_pred))

def batches(X, y, batch_size):
    mini_batches = []
    data = np.hstack((X, y))
    np.random.shuffle(data)
    n_minibatches = data.shape[0] // batch_size
    i = 0
 
    for i in range(n_minibatches + 1):
        mini_batch = data[i * batch_size:(i + 1)*batch_size, :]
        X_mini = mini_batch[:, :-1]
        Y_mini = mini_batch[:, -1].reshape((-1, 1))
        mini_batches.append((X_mini, Y_mini))
    if data.shape[0] % batch_size != 0:
        mini_batch = data[i * batch_size:data.shape[0]]
        X_mini = mini_batch[:, :-1]
        Y_mini = mini_batch[:, -1].reshape((-1, 1))
        mini_batches.append((X_mini, Y_mini))
    return mini_batches


def SGD(data, learning_rate=0.01, n_epochs=1000, k=10, batch_size=40):
    w = np.random.randn(1,data.shape[1]-1)
    b = 0
    epoch=1
    
    while epoch <= n_epochs:
        temp = data.sample(k)
        y = temp.iloc[:,34:].values.tolist()
        x = np.array(temp.drop(""Class"",axis=1))
        L_w = w
        L_b = b
        
        for i in range(k):
            mini_batches = batches(x, y, batch_size)
            for mini_batch in mini_batches:
                x, y = mini_batch
                L_w = (-2/k * x[i]) * (y[i] - np.dot(x[i],w.T) - b)
                L_b = (-2/k) * (y[i] - np.dot(x[i],w.T) - b)
                w = w - learning_rate * L_w
                b = b - learning_rate * L_b
            
        epoch += 1
        learning_rate = learning_rate/1.02
        
    return w,b


def predict(x,w,b):
    y_pred = []
    for i in range(len(x)):
        y = np.asscalar(np.dot(w,x[i])+b)
        y_pred.append(y)
    return np.array(y_pred)


import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

w,b = SGD(data)
x_test = np.array(X_test)
y_test = np.array(Y_test)

from sklearn import preprocessing
scaler = preprocessing.StandardScaler()
x_test = scaler.fit_transform(X_test)
y_pred = predict(x_test,w,b)

print('Mean Squared Error :',mean_squared_error(y_test, y_pred))"
